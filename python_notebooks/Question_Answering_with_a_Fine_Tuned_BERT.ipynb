{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Question Answering with a Fine-Tuned BERT.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "aQl0MMrOGIup",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc79eb89-cbd7-439d-c6fb-4cf227265f83"
      },
      "source": [
        "!pip install transformers\n",
        "!pip install sentencepiece"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.3.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.43)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (0.1.95)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ONLrgJK99TQ"
      },
      "source": [
        "#Importing ML Modules\n",
        "import torch\n",
        "\n",
        "#Importing the QA BERT Class and BERT Tokenizer\n",
        "from transformers import AutoModelForQuestionAnswering, AutoTokenizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Mnv95sX-U9K"
      },
      "source": [
        "model_name = \"bert-large-uncased-whole-word-masking-finetuned-squad\"\n",
        "\n",
        "#Fetching the BERT Pre-trained Model(Pre-trained Weights)\n",
        "model = AutoModelForQuestionAnswering.from_pretrained(model_name)\n",
        "\n",
        "#Fetching the BERT tokenizer (for tokenizing the input)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kWzZP4EN-Zxg"
      },
      "source": [
        "#Question and the answer set\n",
        "question_answer_set = [\n",
        "                       #{'question': 'What shall not be made as a basis of conciliation?', 'answer': 'monetary settlement'},\n",
        "                       #{'question': 'Who shall the settlement be sent to to take action as specified in the recommendation?', 'answer': 'the employer or the district officer'},\n",
        "                       #{'question': 'Who shall provide copies of the settlement as recorded under sub-section (2) to the aggrieved woman and the respondent?', 'answer': 'The Internal Committee or the Local Committee'},\n",
        "                       #{'question': 'When a settlement is reached under sub-section (/), what shall be conducted by the Internal Committee or the Local Committee?', 'answer': 'no further inquiry'}\n",
        "                       {'question': 'To what sectors Sexual Harassment at Workplace (Prevention, Prohibition and Redressal) Act, 2013 applies?', 'answer': 'Organized (govt/private) and unorganised'}\n",
        "                      ]\n",
        "\n",
        "#Separating the questions and the answers\n",
        "questions = []\n",
        "answers = []\n",
        "for pair in question_answer_set:\n",
        "  questions.append(pair['question'])\n",
        "  answers.append(pair['answer'])\n",
        "    \n",
        "#The context to answer the questions\n",
        "t = \"\"\"context = \n",
        "(1) The Internal Committee or, as the case may be, the Local Committee, may, \\\n",
        "before initiating an inquiry under section 11 and at the request of the aggrieved woman take steps to settle \\\n",
        "the matter between her and the respondent through conciliation: \\\n",
        "Provided that no monetary settlement shall be made as a basis of conciliation. \\\n",
        "(2) Where settlement has been arrived at under sub-section (1), the Internal Committee or the Local \\\n",
        "Committee, as the case may be, shall record the settlement so arrived and forward the same to the \\\n",
        "employer or the District Officer to take action as specified in the recommendation. \\\n",
        "(3) The Internal Committee or the Local Committee, as the case may be, shall provide the copies of \\\n",
        "the settlement as recorded under sub-section (2) to the aggrieved woman and the respondent. \\\n",
        "(4) Where a settlement is arrived at under sub-section (1), no further inquiry shall be conducted by the \\\n",
        "Internal Committee or the Local Committee, as the case may be.\n",
        "\"\"\"\n",
        "context = \"\"\"\n",
        "(o) “workplace” includes—\n",
        "(i) any department, organisation, undertaking, establishment, enterprise, institution, office,\n",
        "branch or unit which is established, owned, controlled or wholly or substantially financed by\n",
        "funds provided directly or indirectly by the appropriate Government or the local authority or a\n",
        "Government company or a corporation or a co-operative society;\n",
        "(ii) any private sector organisation or a private venture, undertaking, enterprise, institution,\n",
        "establishment, society, trust, non-governmental organisation, unit or service provider carrying on\n",
        "commercial, professional, vocational, educational, entertainmental, industrial, health services or\n",
        "financial activities including production, supply, sale, distribution or service;\n",
        "(iii) hospitals or nursing homes;\n",
        "(iv) any sports institute, stadium, sports complex or competition or games venue, whether\n",
        "residential or not used for training, sports or other activities relating thereto;\n",
        "(v) any place visited by the employee arising out of or during the course of employment\n",
        "including transportation by the employer for undertaking such journey;\n",
        "(vi) a dwelling place or a house;\n",
        "(p) “unorganised sector” in relation to a workplace means an enterprise owned by individuals or\n",
        "self-employed workers and engaged in the production or sale of goods or providing service of any\n",
        "kind whatsoever, and where the enterprise employs workers, the number of such workers is less than\n",
        "ten\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tYoX33CfKGsr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62b15941-d8a1-4bca-c9f0-0a1f262af0a8"
      },
      "source": [
        "len_pred_words = 0\n",
        "len_shared_words = 0\n",
        "len_org_words = 0\n",
        "accurate = 0\n",
        "for question, org_answer in zip(questions, answers):\n",
        "  #Tokenize the Question and the context\n",
        "  #Concatenate the question and and context and add the special tokens\n",
        "  #Encode the words into word embeddings\n",
        "  input_ids = tokenizer.encode(question, context)\n",
        "\n",
        "  #Converting the token_ids back to tokens to print the answer at the end\n",
        "  tokens = tokenizer.convert_ids_to_tokens(input_ids)\n",
        "\n",
        "  #Creating the segment_id list to specify the segment embedding to be added to the word embedding\n",
        "  #A(0) segment - Question, B(1) segment - Answer Ref Text\n",
        "  sep_index = input_ids.index(tokenizer.sep_token_id)\n",
        "  num_seg_a = sep_index + 1                 #Segment A\n",
        "  num_seg_b = len(input_ids) - num_seg_a    #Segment B\n",
        "\n",
        "  #Constructing the list\n",
        "  segment_ids = [0]*num_seg_a + [1]*num_seg_b  \n",
        "\n",
        "  #Running the model on the given question and answer ref text, specifying the segment_ids alongside\n",
        "  #Fetching the start and end scores after taking dot product with the start and end vectors\n",
        "  scores = model(torch.tensor([input_ids]),                            #The tokens representing our input text\n",
        "                 token_type_ids=torch.tensor([segment_ids]))           #The segment IDs to differentiate question from answer_text\n",
        "               \n",
        "  start_scores = scores.start_logits\n",
        "  end_scores = scores.end_logits  \n",
        "\n",
        "  #Find the token index with the maximum start and end score by applying softmax activation (argmax function)\n",
        "  start_index = torch.argmax(start_scores)\n",
        "  end_index = torch.argmax(end_scores)\n",
        "\n",
        "  #Processing the subword characters added by BERT to get a well organised answer\n",
        "  answer = tokens[start_index]\n",
        "  for i in range(start_index + 1, end_index + 1):\n",
        "      #subword token is added to the previous token to complete a word\n",
        "      if tokens[i][0:2] == '##':\n",
        "          answer += tokens[i][2:]\n",
        "\n",
        "      #else add the token directly to the answer with a whitespace\n",
        "      else:\n",
        "          answer += ' ' + tokens[i]\n",
        "  print('Answer: \"' + answer + '\"')\n",
        "  s = \"\"\"\n",
        "  #Evaluating the performance of the model by calculating Simple Accuracy and F1 measure\n",
        "    len_pred_words += len(answer.split())\n",
        "    len_org_words += len(org_answer.split())\n",
        "    for x, y in zip(answer.lower().split(), org_answer.lower().split()):\n",
        "      if x == y :\n",
        "        len_shared_words += 1\n",
        "    if(answer.lower() == org_answer.lower()) : accurate += 1\n",
        "\n",
        "  #Finding the F1 score, precision and recall\n",
        "  precision = len_shared_words / len_pred_words\n",
        "  recall = len_shared_words / len_org_words\n",
        "  F1 = (2*precision*recall) / (recall + precision)\n",
        "\n",
        "  #printing the simple accuracy and the F1 score\n",
        "  print(\"F1 : {}\".format(F1*100))\n",
        "  print(\"Simple Accuracy : {}\".format(accurate*100/len(questions)))\n",
        "  \"\"\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Answer: \"commercial , professional , vocational , educational , entertainmental , industrial , health services or financial activities including production , supply , sale , distribution or service ; ( iii ) hospitals or nursing homes ; ( iv ) any sports institute , stadium , sports complex or competition or games venue , whether residential or not used for training , sports or other activities relating thereto ; ( v ) any place visited by the employee arising out of or during the course of employment including transportation by the employer for undertaking such journey ; ( vi ) a dwelling place or a house ; ( p ) “ unorganised\"\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "B3sb8hynPjYz",
        "outputId": "3148bac1-f57c-4cec-d334-791368232b7a"
      },
      "source": [
        "\"\"\"\n",
        "#Printing the result of the tokenizer in the form of tokens and token_ids and number of tokens created\n",
        "print('The input has a total of {} tokens.'.format(len(input_ids)))\n",
        "\n",
        "for token, id in zip(tokens, input_ids):\n",
        "    #Add some mark around the [SEP] token, to make it stand out.\n",
        "    if id == tokenizer.sep_token_id:\n",
        "        print('-------------------')\n",
        "\n",
        "    #Print the token and the corresponding ID\n",
        "    print('{:<12} {}'.format(token, id))\n",
        "\n",
        "    #Add some mark around the [SEP] token, to make it stand out.\n",
        "    if id == tokenizer.sep_token_id:\n",
        "        print('-------------------')\n",
        "\"\"\"\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\n#Printing the result of the tokenizer in the form of tokens and token_ids and number of tokens created\\nprint('The input has a total of {} tokens.'.format(len(input_ids)))\\n\\nfor token, id in zip(tokens, input_ids):\\n    #Add some mark around the [SEP] token, to make it stand out.\\n    if id == tokenizer.sep_token_id:\\n        print('-------------------')\\n\\n    #Print the token and the corresponding ID\\n    print('{:<12} {}'.format(token, id))\\n\\n    #Add some mark around the [SEP] token, to make it stand out.\\n    if id == tokenizer.sep_token_id:\\n        print('-------------------')\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    }
  ]
}